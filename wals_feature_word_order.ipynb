{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cat_len=[20,12,29,8,17,24,26,7,13,4,32]\n",
    "feature_cat_names=['Phonology','Morphology','Nominal Categories','Nominal Syntax','\tVerbal Categories','Word Order','Simple Clauses','Complex Sentences','Lexicon','Other','Word Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2681\n",
      "{'ben': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 2, 0, 0, 4, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5], 'guj': [1, 1, 1, 0, 1, 6, 2, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 4, 3, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'hin': [1, 1, 1, 4, 1, 1, 2, 1, 1, 5, 1, 5, 5, 2, 0, 2, 2, 1, 1, 2, 1, 3, 8, 2, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 4, 3, 0, 0, 0, 4, 0, 0, 1, 2, 5, 0, 2, 2, 4, 0, 1, 5], 'knd': [1, 1, 1, 7, 1, 2, 2, 5, 1, 5, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 3, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 4, 6, 0, 0, 0, 4, 0, 0, 2, 1, 4, 0, 2, 1, 4, 0, 1, 5], 'mhi': [1, 1, 1, 2, 1, 2, 2, 4, 1, 1, 1, 5, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 2, 0, 0, 4, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mym': [1, 1, 1, 2, 0, 2, 2, 0, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 4, 6, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'pan': [1, 1, 1, 7, 1, 1, 2, 1, 1, 5, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 8, 0, 0, 0, 3, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 4, 3, 0, 0, 0, 4, 0, 0, 0, 0, 5, 0, 0, 0, 4, 0, 0, 0], 'tel': [1, 1, 1, 2, 1, 6, 2, 5, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 4, 6, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tml': [1, 1, 1, 2, 1, 6, 2, 4, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 3, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 4, 6, 0, 0, 0, 4, 0, 0, 0, 0, 5, 0, 0, 0, 4, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "fin='language.csv'\n",
    "dataset=[]\n",
    "upd_dataset=[]\n",
    "cnt=0\n",
    "with open(fin,errors='ignore') as file:\n",
    "    reader = csv.reader(file)\n",
    "    data = list(reader)\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "wals_lan=['ben','hin','tel','tml','guj','mhi','pan','mym','knd']\n",
    "lan_dict=dict()\n",
    "for row in data:\n",
    "    wals_code=row[0]\n",
    "    if wals_code in wals_lan:\n",
    "        cur_features=list()\n",
    "        for i in range(96,96+24):\n",
    "            l=row[i].split()\n",
    "            if len(l)>1:\n",
    "                cur_features.append(int(l[0]))\n",
    "            else:\n",
    "                cur_features.append(int(0))\n",
    "                \n",
    "        for i in range(170,len(row)):\n",
    "            l=row[i].split()\n",
    "            if len(l)>1:\n",
    "                cur_features.append(int(l[0]))\n",
    "            else:\n",
    "                cur_features.append(int(0))\n",
    "\n",
    "\n",
    "                \n",
    "        lan_dict[wals_code]=cur_features\n",
    "        \n",
    "print(lan_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(l1, l2):\n",
    "    for i in range(0,len(l1)):\n",
    "        \n",
    "        if l1[i]!=0 and l2[i]!=0:\n",
    "            continue\n",
    "        else:\n",
    "            l1[i]=0\n",
    "            l2[i]=0\n",
    "    return l1,l2\n",
    "\n",
    "\n",
    "\n",
    "def removeZeroes(l):\n",
    "    new_l=list()\n",
    "    \n",
    "    for i in l:\n",
    "        if i!=0:\n",
    "            new_l.append(i)\n",
    "    return new_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCosineSimilarity(d1, d2):\n",
    "    cos_sim = np.dot(d1, d2)/(np.linalg.norm(d1)*np.linalg.norm(d2))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'ascii_name', 'akb': 'akabiada', 'akc': 'akacari', 'akk': 'akakede', 'agm': 'angami', 'ao': 'ao', 'apt': 'apatani', 'apk': 'apucikwar', 'ass': 'assamese', 'awd': 'awadhi', 'bdg': 'badaga', 'bgi': 'bagri', 'blt': 'balti', 'baw': 'bawm', 'ben': 'bengali', 'bkb': 'betta kurumba', 'bhi': 'bhili', 'bho': 'bhojpuri', 'bhu': 'bhumij', 'bod': 'bodo', 'boq': 'bokar', 'boj': 'bori', 'bkt': 'brokskat', 'bgn': 'bugun', 'ghr': 'bunan', 'bya': 'byansi', 'chg': 'chang', 'chd': 'chaudangsi', 'cmr': 'chin mara', 'drm': 'darma', 'deu': 'deuri', 'dig': 'digaro', 'dms': 'dimasa', 'dgi': 'dogri', 'gdk': 'gadaba kondekor', 'gal': 'galo', 'gar': 'garo', 'goj': 'gojri', 'gon': 'gondi', 'gan': 'great andamanese', 'guj': 'gujarati', 'gdb': 'gutob', 'hlb': 'halbi', 'hin': 'hindi', 'hma': 'hmar', 'ho': 'ho', 'idu': 'idu', 'ipi': 'indopakistani sign language indian dialects', 'jad': 'jad', 'jrw': 'jarawa in andamans', 'joh': 'johari', 'jun': 'juang', 'jug': 'jugli', 'kbi': 'kabui', 'kac': 'kachari', 'xns': 'kanashi', 'knd': 'kannada', 'kas': 'kashmiri', 'khg': 'khaling', 'khr': 'kharia', 'khs': 'khasi', 'knn': 'kinnauri', 'kod': 'kodava', 'kok': 'kokborok', 'kkz': 'kokni', 'kol': 'kolami', 'kda': 'konda', 'kkn': 'konkani', 'kku': 'korku', 'kot': 'kota', 'koy': 'koya', 'kui': 'kui in india', 'kum': 'kumauni', 'kur': 'kurukh', 'kuv': 'kuvi', 'lad': 'ladakhi', 'lmn': 'lamani', 'lep': 'lepcha', 'lim': 'limbu', 'lot': 'lotha', 'lun': 'lungchang', 'mgh': 'magahi', 'mai': 'maithili', 'mym': 'malayalam', 'mto': 'malto', 'mhi': 'marathi', 'mrc': 'marchha', 'mwc': 'mawchi', 'mei': 'meithei', 'mij': 'miju', 'mik': 'mikir', 'mil': 'milang', 'mhl': 'miri hill', 'msg': 'mising', 'miz': 'mizo', 'mun': 'mundari', 'nma': 'naga mao', 'npn': 'naga pidgin', 'ngt': 'naga tangkhul', 'nze': 'naga zeme', 'nah': 'nahali', 'nnc': 'nancowry', 'nic': 'nicobarese', 'nca': 'nicobarese car', 'noc': 'nocte', 'nyk': 'nyamkad', 'nis': 'nyishi', 'ong': 'onge', 'oya': 'oriya', 'oko': 'oriya kotia', 'pte': 'paite', 'pan': 'panjabi', 'prd': 'parji dravidian', 'ptt': 'pattani', 'pen': 'pengo', 'prk': 'purki', 'rji': 'raji', 'ral': 'ralte', 'rem': 'remo', 'stl': 'santali', 'sem': 'sema', 'skw': 'shekhawati', 'shd': 'sherdukpen', 'smp': 'shompen', 'skk': 'sikkimese', 'sdh': 'sindhi', 'sor': 'sora', 'spi': 'spitian', 'slg': 'sulung', 'tml': 'tamil', 'tsp': 'tamil spoken', 'tao': 'tarao', 'tel': 'telugu', 'thd': 'thadou', 'tni': 'tinani', 'tod': 'tod', 'tda': 'toda', 'tgl': 'tshangla', 'tul': 'tulu', 'tvt': 'tutsa', 'vas': 'vasavi'}\n"
     ]
    }
   ],
   "source": [
    "fin='indian_languages.csv'\n",
    "ind_data=[]\n",
    "with open(fin,errors='ignore') as file:\n",
    "    reader = csv.reader(file)\n",
    "    ind_data=list(reader)\n",
    "\n",
    "ind_lan_dict=dict()   \n",
    "for row in ind_data:\n",
    "    ind_lan_dict[row[3]]=row[0]\n",
    "print(ind_lan_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "dataset=[]\n",
    "lan_names=[]\n",
    "lan_codes=[]\n",
    "for lan in lan_dict:\n",
    "    lan_codes.append(lan)\n",
    "    lan_names.append(ind_lan_dict[lan])\n",
    "    fv=lan_dict[lan]\n",
    "    dataset.append(fv)\n",
    "\n",
    "dataset_array=np.array(dataset)\n",
    "output=[]\n",
    "for i in range(0,len(dataset_array)):\n",
    "    for j in range(0,len(dataset_array)):\n",
    "        if i<j:\n",
    "            val=round(calculateCosineSimilarity(dataset_array[i],dataset_array[j]),2)\n",
    "            if math.isnan(val)==False:\n",
    "                s='Cosine similarity between '+lan_names[i]+' and '+lan_names[j]+' - '+str(val)\n",
    "                output.append(s)\n",
    "                \n",
    "with open('.//outputs//word_order.txt', 'w') as f:\n",
    "    for item in output:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
