{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyexpat import model\n",
    "from gensim.models import Word2Vec, KeyedVectors,FastText\n",
    "import numpy as np\n",
    "import os\n",
    "current_path = ''#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt \n",
    "from aksharamukha import transliterate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_mapping = {'hi':'Hindi',\n",
    "                'bn':'Bengali',\n",
    "                'ta':'Tamil',\n",
    "                'gu':'Gujarati',\n",
    "                'te':'Telugu',\n",
    "                'kn':'Kannada',\n",
    "                'ml':'Malayalam',\n",
    "                'mr':'Marathi',\n",
    "                'pa':'Punjabi (Gurmukhi)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_lst = ['bn','ta','gu','te','kn','ml','mr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_lst = ['50','100']\n",
    "emb_lst = ['fasttext','cbow','sg']\n",
    "pca = PCA(n_components=2)\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embb(loc,emb,lang,dim):\n",
    "    words_vec = []\n",
    "    dirpath=current_path+lang+\"/\"+dim+\"/\"+emb+\"/\"+lang+\"-d\"+dim+\"-m2-\"+emb+\".model\"\n",
    "    if emb == 'fasttext':\n",
    "        model = FastText.load(dirpath) #load the model\n",
    "    else:\n",
    "        model = Word2Vec.load(dirpath) #load the model\n",
    "    filepath = current_path+loc+lang+\".txt\"\n",
    "    with open(filepath,'r',encoding='utf-8') as file:\n",
    "        found = []\n",
    "        for lines in file:\n",
    "            words=lines.strip()\n",
    "            try:\n",
    "                if lang == 'hi' or emb == 'fasttext':\n",
    "                    sg_emb1 = model.wv[words]\n",
    "                else:\n",
    "                    new_word1= transliterate.process(lang_mapping[lang],\n",
    "                                                     'Devanagari',\n",
    "                                                     words,\n",
    "                                                     nativize = False)\n",
    "                    sg_emb1 = model.wv[new_word1]\n",
    "                words_vec.append(sg_emb1)\n",
    "                found.append(1)\n",
    "            except:\n",
    "                words_vec.append([-0.1]*int(dim))\n",
    "                found.append(0)\n",
    "                #print(\"words not found are : \",words)\n",
    "    print(\"{}:found {} out of {} in {} {}\".format(lang,sum(found),len(found),emb,dim))\n",
    "    return np.array(words_vec),np.array(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plott(eng_map,i,count,pca_result,lng_lst):\n",
    "    for lang_index in range(len(lng_lst)):\n",
    "        plt.scatter([pca_result[(count*lang_index)+i,0]],\n",
    "                    [pca_result[(count*lang_index)+i,1]],\n",
    "                    label=lang_mapping[lng_lst[lang_index]])\n",
    "    plt.legend()\n",
    "    plt.xlim([-0.1, 1.1])\n",
    "    plt.ylim([-0.1, 1.1])\n",
    "    plt.title(eng_words[i])\n",
    "    plt.savefig(current_path+'plots/'+dim+'/'+emb+'/'+eng_map[eng_words[i]]+'_'+eng_words[i]+'.jpg')\n",
    "    #plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter(found):\n",
    "    filter = []\n",
    "    for i in range(len(found)):\n",
    "        if found[i]:\n",
    "            filter.append(i)\n",
    "    return filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(eng_map,eng_words,emb,dim,found,emb_dct):\n",
    "    count = int(sum(found))\n",
    "    filter = get_filter(found)\n",
    "    eng_words = eng_words[filter]\n",
    "    lng_lst = list(emb_dct.keys())\n",
    "    new_lst = []\n",
    "    for lang in lng_lst:\n",
    "        new_lst.extend(emb_dct[lang][filter].tolist())\n",
    "    new_lst = np.array(new_lst)\n",
    "    pca_result = pca.fit_transform(new_lst)\n",
    "    pca_result = MinMaxScaler().fit_transform(pca_result)\n",
    "    for i in range(count):\n",
    "        plott(eng_map,i,count,pca_result,lng_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eng_words():\n",
    "    eng_word = []\n",
    "    filepath = current_path+\"test/en.txt\"\n",
    "    with open(filepath,'r',encoding='utf-8') as file:\n",
    "        for lines in file:\n",
    "            eng_word.append(lines.strip())\n",
    "    return np.array(eng_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eng_map():\n",
    "    eng_map = {}\n",
    "    filepath = current_path+\"en_map.txt\"\n",
    "    with open(filepath,'r',encoding='utf-8') as file:\n",
    "        for lines in file:\n",
    "            a = lines.strip().split(',')\n",
    "            eng_map[a[0]] = a[1]\n",
    "    return eng_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(eng_map,eng_words,emb,dim,found,emb_dct):\n",
    "    count = int(sum(found))\n",
    "    filter = get_filter(found)\n",
    "    eng_words = eng_words[filter]\n",
    "    dct = {}\n",
    "    langs = list(emb_dct.keys())\n",
    "    for i in range(len(langs)-1):\n",
    "        for j in range(i+1,len(langs)):\n",
    "            key = langs[i]+'_'+langs[j]\n",
    "            lang1 = emb_dct[langs[i]][filter]\n",
    "            lang2 = emb_dct[langs[j]][filter]\n",
    "            dct[key] = [[0,0] for _ in range(11)]\n",
    "            for k in range(count):\n",
    "                a = cosine_similarity(lang1[k:k+1],lang2[k:k+1])\n",
    "                a = a.tolist()[0][0]\n",
    "                dct[key][int(eng_map[eng_words[k]])][0] += a\n",
    "                dct[key][int(eng_map[eng_words[k]])][1] += 1\n",
    "            for k in range(11):\n",
    "                dct[key][k] = dct[key][k][0] / dct[key][k][1]\n",
    "    file = open(current_path+'cos_sim/'+dim+'/'+emb+'.csv','w')\n",
    "    file.write('langs,fruits,plants,food,vegetables,colors,animals,possession,family,occupation,places,household-items\\n')\n",
    "    for key,value in dct.items():\n",
    "        file.write(key+',')\n",
    "        file.write(','.join(map(str,value)))\n",
    "        file.write('\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi:found 50 out of 50 in cbow 50\n",
      "bn:found 48 out of 50 in cbow 50\n",
      "ta:found 48 out of 50 in cbow 50\n",
      "gu:found 49 out of 50 in cbow 50\n",
      "te:found 50 out of 50 in cbow 50\n",
      "kn:found 47 out of 50 in cbow 50\n",
      "ml:found 49 out of 50 in cbow 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautamc/Downloads/project/venv/lib/python3.8/site-packages/aksharamukha/transliterate.py:337: UserWarning: Source script: Marathi not found in the list of scripts supported. The text will not be transliterated.\n",
      "  warnings.warn(script_not_found)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr:found 49 out of 50 in cbow 50\n",
      "hi:found 50 out of 50 in cbow 100\n",
      "bn:found 48 out of 50 in cbow 100\n",
      "ta:found 48 out of 50 in cbow 100\n",
      "gu:found 49 out of 50 in cbow 100\n",
      "te:found 50 out of 50 in cbow 100\n",
      "kn:found 47 out of 50 in cbow 100\n",
      "ml:found 49 out of 50 in cbow 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautamc/Downloads/project/venv/lib/python3.8/site-packages/aksharamukha/transliterate.py:337: UserWarning: Source script: Marathi not found in the list of scripts supported. The text will not be transliterated.\n",
      "  warnings.warn(script_not_found)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr:found 49 out of 50 in cbow 100\n",
      "hi:found 50 out of 50 in sg 50\n",
      "bn:found 48 out of 50 in sg 50\n",
      "ta:found 48 out of 50 in sg 50\n",
      "gu:found 49 out of 50 in sg 50\n",
      "te:found 50 out of 50 in sg 50\n",
      "kn:found 47 out of 50 in sg 50\n",
      "ml:found 49 out of 50 in sg 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautamc/Downloads/project/venv/lib/python3.8/site-packages/aksharamukha/transliterate.py:337: UserWarning: Source script: Marathi not found in the list of scripts supported. The text will not be transliterated.\n",
      "  warnings.warn(script_not_found)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr:found 49 out of 50 in sg 50\n",
      "hi:found 50 out of 50 in sg 100\n",
      "bn:found 48 out of 50 in sg 100\n",
      "ta:found 48 out of 50 in sg 100\n",
      "gu:found 49 out of 50 in sg 100\n",
      "te:found 50 out of 50 in sg 100\n",
      "kn:found 47 out of 50 in sg 100\n",
      "ml:found 49 out of 50 in sg 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautamc/Downloads/project/venv/lib/python3.8/site-packages/aksharamukha/transliterate.py:337: UserWarning: Source script: Marathi not found in the list of scripts supported. The text will not be transliterated.\n",
      "  warnings.warn(script_not_found)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr:found 49 out of 50 in sg 100\n"
     ]
    }
   ],
   "source": [
    "for emb in emb_lst[1:]:\n",
    "    for dim in dim_lst:\n",
    "        hi_emb,_ = get_embb('train/',emb,'hi',dim)\n",
    "        for lang in lang_lst:\n",
    "            temp_emb,found  = get_embb('train/',emb,lang,dim)\n",
    "            filter = get_filter(found)\n",
    "            models[lang+'_'+dim+'_'+emb] = LinearRegression().fit(hi_emb[filter],temp_emb[filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_words = get_eng_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_map = get_eng_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi:found 60 out of 60 in fasttext 50\n",
      "bn:found 60 out of 60 in fasttext 50\n",
      "ta:found 60 out of 60 in fasttext 50\n",
      "gu:found 60 out of 60 in fasttext 50\n",
      "te:found 60 out of 60 in fasttext 50\n",
      "kn:found 60 out of 60 in fasttext 50\n",
      "ml:found 60 out of 60 in fasttext 50\n",
      "mr:found 60 out of 60 in fasttext 50\n",
      "hi:found 60 out of 60 in fasttext 100\n",
      "bn:found 60 out of 60 in fasttext 100\n",
      "ta:found 60 out of 60 in fasttext 100\n",
      "gu:found 60 out of 60 in fasttext 100\n",
      "te:found 60 out of 60 in fasttext 100\n",
      "kn:found 60 out of 60 in fasttext 100\n",
      "ml:found 60 out of 60 in fasttext 100\n",
      "mr:found 60 out of 60 in fasttext 100\n",
      "hi:found 58 out of 60 in cbow 50\n",
      "bn:found 54 out of 60 in cbow 50\n",
      "ta:found 57 out of 60 in cbow 50\n",
      "gu:found 58 out of 60 in cbow 50\n",
      "te:found 55 out of 60 in cbow 50\n",
      "kn:found 46 out of 60 in cbow 50\n",
      "ml:found 56 out of 60 in cbow 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautamc/Downloads/project/venv/lib/python3.8/site-packages/aksharamukha/transliterate.py:337: UserWarning: Source script: Marathi not found in the list of scripts supported. The text will not be transliterated.\n",
      "  warnings.warn(script_not_found)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr:found 59 out of 60 in cbow 50\n",
      "hi:found 58 out of 60 in cbow 100\n",
      "bn:found 54 out of 60 in cbow 100\n",
      "ta:found 57 out of 60 in cbow 100\n",
      "gu:found 58 out of 60 in cbow 100\n",
      "te:found 55 out of 60 in cbow 100\n",
      "kn:found 46 out of 60 in cbow 100\n",
      "ml:found 56 out of 60 in cbow 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautamc/Downloads/project/venv/lib/python3.8/site-packages/aksharamukha/transliterate.py:337: UserWarning: Source script: Marathi not found in the list of scripts supported. The text will not be transliterated.\n",
      "  warnings.warn(script_not_found)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr:found 59 out of 60 in cbow 100\n",
      "hi:found 58 out of 60 in sg 50\n",
      "bn:found 54 out of 60 in sg 50\n",
      "ta:found 57 out of 60 in sg 50\n",
      "gu:found 58 out of 60 in sg 50\n",
      "te:found 55 out of 60 in sg 50\n",
      "kn:found 46 out of 60 in sg 50\n",
      "ml:found 56 out of 60 in sg 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautamc/Downloads/project/venv/lib/python3.8/site-packages/aksharamukha/transliterate.py:337: UserWarning: Source script: Marathi not found in the list of scripts supported. The text will not be transliterated.\n",
      "  warnings.warn(script_not_found)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr:found 59 out of 60 in sg 50\n",
      "hi:found 58 out of 60 in sg 100\n",
      "bn:found 54 out of 60 in sg 100\n",
      "ta:found 57 out of 60 in sg 100\n",
      "gu:found 58 out of 60 in sg 100\n",
      "te:found 55 out of 60 in sg 100\n",
      "kn:found 46 out of 60 in sg 100\n",
      "ml:found 56 out of 60 in sg 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautamc/Downloads/project/venv/lib/python3.8/site-packages/aksharamukha/transliterate.py:337: UserWarning: Source script: Marathi not found in the list of scripts supported. The text will not be transliterated.\n",
      "  warnings.warn(script_not_found)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr:found 59 out of 60 in sg 100\n"
     ]
    }
   ],
   "source": [
    "for emb in emb_lst:\n",
    "    for dim in dim_lst:\n",
    "        emb_dct = {}\n",
    "        emb_dct['hi'],found = get_embb('test/',emb,'hi',dim)\n",
    "        for lang in lang_lst:\n",
    "            temp_emb,new_found = get_embb('test/',emb,lang,dim)\n",
    "            emb_dct[lang] = models[lang+'_'+dim+'_'+emb].predict(temp_emb)\n",
    "            found = found & new_found\n",
    "        \n",
    "        cos_sim(eng_map,eng_words,emb,dim,found,emb_dct)\n",
    "        plot_all(eng_map,eng_words,emb,dim,found,emb_dct)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff47133907a3d35a24ac3870c48b81ce2ee5c07ef508bc28b7c1c2522db32e77"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
